{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import numpy as np\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from CSV\n",
    "\n",
    "`pd.read_csv`: takes in a csv and returns a pandas dataframe.\n",
    "\n",
    "`train_test_split`: splits arrays or matrices into random train and tests sets.\n",
    "- `train_size`: 0-1 value representing the percent of the dataset in the training set.\n",
    "- `test_size`: see above, but for test set.\n",
    "- `random_state`: state used for shuffling. To replicate results, use same `random_state`.\n",
    "\n",
    "In the next cell, we remove the SalePrice labelled column from the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from train csv\n",
    "data = pd.read_csv('../datasets/kaggle-house-prices/train.csv', index_col=\"Id\")\n",
    "X_test_full = pd.read_csv('../datasets/kaggle-house-prices/test.csv', index_col=\"Id\")\n",
    "\n",
    "# Drop rows with missing label\n",
    "data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "data.dropna(axis=1, inplace=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate label from features\n",
    "y = data.SalePrice\n",
    "X = data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Run train_test_split to split data 80% train 20% validation\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tools to get dataframe information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full.describe()\n",
    "X_train_full.head()\n",
    "X_train_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Low cardinality columns: columns that have a low number of unique items. This allows us to do some learning based on these cols without adding too much noise.\n",
    "\n",
    "Numeric columns: columns with numeric values as opposed to \"object\" columns.\n",
    "\n",
    "In this example, we select the columns to train based on columns that are numeric and columns with low cardinality. You may want to change this depending on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low cardinality columns\n",
    "# Returns a list of categorical columns with low cardinality\n",
    "    # Unique values < 10\n",
    "low_cardinality_cols = [colName for colName in X_train_full.columns \n",
    "                        if X_train_full[colName].nunique() < 10 and \n",
    "                            X_train_full[colName].dtype == \"object\"]\n",
    "\n",
    "# Numeric columns\n",
    "# Returns a list of numeric columns\n",
    "numeric_cols = [colName for colName in X_train_full.columns\n",
    "                if X_train_full[colName].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Copy only selected columns (low cardinality and numeric)\n",
    "selected_cols = numeric_cols + low_cardinality_cols\n",
    "X_train = X_train_full[selected_cols].copy()\n",
    "X_valid = X_valid_full[selected_cols].copy()\n",
    "X_test = X_test_full[selected_cols].copy()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train_full[numeric_cols].copy()\n",
    "X_valid_numeric = X_valid_full[numeric_cols].copy()\n",
    "X_test_numeric = X_test_full[numeric_cols].copy()\n",
    "\n",
    "X_train_categorical = X_train_full[low_cardinality_cols].copy()\n",
    "X_valid_categorical = X_valid_full[low_cardinality_cols].copy()\n",
    "X_test_categorical = X_test_full[low_cardinality_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variables\n",
    "\n",
    "Drop Categorical: Remove all columns with non-numeric data.\n",
    "\n",
    "One-Hot encoding: Add \"one-hot\" columns to represent different categories.\n",
    "\n",
    "Ordinal: Assign each category a different numeric value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop categorical\n",
    "\n",
    "Simply remove all columns with non-numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different way to select numeric columns than above\n",
    "X_train_numeric = X_train.select_dtypes(exclude=['object'])\n",
    "X_valid_numeric = X_train.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot encoding\n",
    "\n",
    "A technique used to split numeric columns with multiple values into multiple columns with one column being \"hot\" (1) and the rest 0.\n",
    "\n",
    "For example:\n",
    "Size becomes Small, Medium, Large\n",
    "|Size|Small|Medium|Large\n",
    "|-|-|-|-|\n",
    "|Small|1|0|0\n",
    "|Large|0|0|1\n",
    "|Medium|0|1|0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-Hot Encoding\n",
    "OHEncoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OHEncoder.fit(X_train[low_cardinality_cols])\n",
    "OH_train_cols = pd.DataFrame(OHEncoder.transform(X_train[low_cardinality_cols]))\n",
    "OH_valid_cols = pd.DataFrame(OHEncoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "OH_train_cols.index = X_train.index\n",
    "OH_valid_cols.index = X_valid.index\n",
    "\n",
    "X_train_OH = pd.concat([X_train_numeric, OH_train_cols], axis=1)\n",
    "X_valid_OH = pd.concat([X_valid_numeric, OH_valid_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a very easy way to do one-hot encoding\n",
    "X_train_OH = pd.get_dummies(X_train)\n",
    "X_valid_OH = pd.get_dummies(X_valid)\n",
    "X_test_OH = pd.get_dummies(X_test)\n",
    "X_train_OH.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding\n",
    "Change categorical columns to numeric single-column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Collecting non-numeric columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Here we need to check if there are any unknown values in the validation set, do this by checking\n",
    "# if validation set is a subset of training set\n",
    "good_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "\n",
    "# Remove columns with unknown data\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "ordinal_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "ordinal_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Create ordinal encoder and replace values in good_cols with the ordinal encoded values\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "ordinal_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n",
    "ordinal_X_train[good_label_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning\n",
    "min_lotArea = X_train.LotArea.min()\n",
    "max_lotArea = X_train.LotArea.max()\n",
    "num_bins = 50\n",
    "bins = np.linspace(min_lotArea, max_lotArea, num_bins)\n",
    "labels = [str(i) for i in range(num_bins-1)]\n",
    "\n",
    "lotArea_binned = pd.cut(X_train.LotArea, bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imputation\n",
    "imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(imputer.fit_transform(X_valid))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b9387b62044525a462bf700ac9a789d422f96e47157fcf6753215851c82f737"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
